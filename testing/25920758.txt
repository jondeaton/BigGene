

position: 25920756


primaryMapped read 1
- start: 25920668
- end: 25920756
- readName: HWI-D00684:221:HNWKCADXX:1:1109:19666:39303
- quality: BFBFFFFFFBFFFBBFFFFFBBB<0B<<BFFFFFFFFFFFFIIIIIIIIIIFBFFIIIIIFFFIFFIFFFFFFFIIIIFFIIIFFFFF
- cigar: 88M
- recordGroupName: None
- recordGroupSample: 9970


primaryMapped read 2
- start: 25920247
- end: 25920345
- readName: HWI-D00684:221:HNWKCADXX:1:1109:19666:39303
- quality: <BBFFBFFFFFFFIIFFBFF<FBFBFFIIIIFIIIFIFFFIFIFFFFFIIIIIFFFFFIIFFIIIIFFFIIFFFFFIFFFBFFBFBBFBFFFFBFFF<
- cigar: 89M
- recordGroupName: None
- recordGroupSample: 9970



# The one duplicate that I am still missing
readName: HWI-D00684:216:HTCFTADXX:1:1107:11746:90551


One of the 106 false positives that I have
readName: HWI-D00684:221:HNWKCADXX:2:1213:7143:86120
	- This read is a top scoring read!
	- scoreBucket = 3029
	- my score: 3454!!!!! WRONG
	- cigar: 88m
	- fivePrimePosition: 2629252
	- readInFragment: 0

- Even when correcting the score, it has the same read1 and read2 ref pos as
HWI-D00684:216:HTCFTADXX:2:2214:18429:5472
- which has a score of 3043 (in mine)

The issue is that you can't just group by reference position, but you also have to group by referenceName and strand

some more false positives
HWI-D00684:221:HNWKCADXX:1:1205:12143:89802
HWI-D00684:216:HTCFTADXX:1:2104:7648:67154




Reads which are still wrong on the big dataset (there are 21 unmapped false positives)


HWI-D00684:217:HT7M7ADXX:1:1201:15447:7439
HWI-D00684:221:HNWKCADXX:2:2116:13530:83270
HWI-D00684:217:HT7M7ADXX:2:1212:15188:80677
HWI-D00684:217:HT7M7ADXX:1:2112:2614:61243
